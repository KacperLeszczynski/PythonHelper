{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f589dec6-3240-4d36-a236-7ca6a3422b69",
   "metadata": {},
   "source": [
    "## Scripts to build vector databases needed for RAG and fine tuning\n",
    "In this file there will be scripts for getting data from python docs and stack overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6310583-4f28-485c-b406-e2b59db751dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!where python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a915dc4-d7d3-41f3-84bd-b5e6c0b5fd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "768fc10b-6430-40e9-8798-099e176c1f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_versions = [\"3.10\",\"3.11\",\"3.12\",\"3.13\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5b821c-25b9-4236-90e7-5c1826e3e072",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_text_preserving_structure(html_text):\n",
    "    soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "\n",
    "    structured_text = []\n",
    "\n",
    "    # Pobieramy elementy w takiej kolejnoÅ›ci, jak wystÄ™pujÄ… w HTML\n",
    "    for el in soup.find_all([\"h1\", \"h2\", \"h3\", \"p\", \"li\", \"blockquote\", \"code\", \"pre\", \"div\", \"span\"]):\n",
    "        tag = el.name\n",
    "        text = el.get_text(separator=\" \", strip=True)\n",
    "\n",
    "        if tag == \"pre\" or (tag == \"div\" and \"pre\" in el.get(\"class\", [])):\n",
    "            structured_text.append(f\"```python\\n{text}\\n```\")\n",
    "\n",
    "        elif tag == \"code\":\n",
    "            structured_text.append(f\"`{text}`\")\n",
    "\n",
    "        elif tag == \"span\" and \"pre\" in el.get(\"class\", []):\n",
    "            structured_text.append(f\"`{text}`\")\n",
    "\n",
    "        elif tag in [\"h1\", \"h2\", \"h3\"]:\n",
    "            structured_text.append(f\"\\n## {text}\\n\")\n",
    "\n",
    "        elif tag == \"li\":\n",
    "            structured_text.append(f\"- {text}\")\n",
    "\n",
    "        elif tag == \"blockquote\":\n",
    "            structured_text.append(f\"> {text}\")\n",
    "\n",
    "        else:\n",
    "            structured_text.append(text)\n",
    "\n",
    "    return \"\\n\".join(structured_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b82579-1290-4b55-ac8b-f8334bc24c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "python_docs = []\n",
    "\n",
    "for version in python_versions:\n",
    "\n",
    "    website_url = f\"https://docs.python.org/{version}/library/\"\n",
    "    index_url = urljoin(website_url, \"index.html\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(index_url)\n",
    "        response.raise_for_status()\n",
    "    \n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "        links = soup.find_all(\"a\")\n",
    "\n",
    "        for link in links:\n",
    "            if link.has_attr(\"href\"):\n",
    "                href = link[\"href\"]\n",
    "                print(f\"Original href: {href}\")\n",
    "    \n",
    "                base_href, _, fragment = href.partition(\"#\")\n",
    "    \n",
    "                new_link = urljoin(website_url, base_href)\n",
    "    \n",
    "                if not new_link.startswith(website_url):\n",
    "                    continue\n",
    "    \n",
    "                try:\n",
    "                    new_link_response = requests.get(new_link)\n",
    "                    new_link_response.raise_for_status()\n",
    "    \n",
    "                    new_soup = BeautifulSoup(new_link_response.text, \"html.parser\")\n",
    "    \n",
    "                    wrapper_div = new_soup.find(\"div\", class_=\"bodywrapper\")\n",
    "    \n",
    "                    if wrapper_div:\n",
    "                        formatted_text = extract_text_preserving_structure(str(wrapper_div))\n",
    "                        python_docs.append({\"version\": version, \"url\": new_link, \"text\": formatted_text})\n",
    "                        \n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    print(f\"BÅ‚Ä…d pobierania\")\n",
    "        print(f\"Succesfully loaded python {version} documentation\")\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"BÅ‚Ä…d pobierania strony gÅ‚Ã³wnej\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d0eabb-65e7-4ab9-8105-6c3568b3ebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(python_docs[0]['text'][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2de4f4-07e3-4e80-aff4-3ef7bdd14d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397a268b-f873-4938-a0c8-8496b24ae555",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"backup.pkl\", \"wb\") as f:\n",
    "    pickle.dump(python_docs, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16bb735-0661-49e1-a928-1af6572d6ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"backup.pkl\", \"rb\") as f:\n",
    "    python_docs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1d81e7-07f3-488d-830c-ad174d7994bd",
   "metadata": {},
   "source": [
    "### StackOverflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4973c71-e18b-4bbe-8fbf-52c534cc8a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ab3ff78-adaf-4871-b630-4b5fefac161e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ec83808-9276-41f8-b614-64a39e76d9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "STACK_EXCHANGE_API_KEY = os.getenv(\"STACK_EXCHANGE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86ecad4c-d87c-4c8c-b55a-12a82decd0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stackoverflow_questions(tag=\"python\", intitle=None, page=1, pagesize=100):\n",
    "    url = \"https://api.stackexchange.com/2.3/search\"\n",
    "    params = {\n",
    "        \"order\": \"desc\",\n",
    "        \"sort\": \"creation\",\n",
    "        \"tagged\": tag,\n",
    "        \"site\": \"stackoverflow\",\n",
    "        \"pagesize\": pagesize,\n",
    "        \"page\": page,\n",
    "        \"filter\": \"!9_bDDxJY5\",\n",
    "        \"key\": STACK_EXCHANGE_API_KEY\n",
    "    }\n",
    "    \n",
    "    if intitle:\n",
    "        params[\"intitle\"] = intitle\n",
    "\n",
    "    retries = 3\n",
    "    for attempt in range(retries):\n",
    "        response = requests.get(url, params=params)\n",
    "        print(response.status_code)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json().get(\"items\", [])\n",
    "\n",
    "        elif response.status_code == 429:\n",
    "            wait_time = 5 * (attempt + 1)\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd93d7ee-1016-4712-916a-64df0ed2691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b375f821-09d2-4df9-86db-f86fd2f16a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_all_stackoverflow_questions(tag=\"python\", intitle=None, max_pages=5, pagesize=20):\n",
    "    all_questions = []\n",
    "    for page in range(1, max_pages + 1):\n",
    "        questions = fetch_stackoverflow_questions(tag, intitle, page, pagesize)\n",
    "        if not questions:\n",
    "            break\n",
    "        all_questions.extend(questions)\n",
    "        time.sleep(2)\n",
    "\n",
    "    return all_questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b83e115d-d839-4630-a88d-6d8e713cef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_best_answer(question_id):\n",
    "    url = f\"https://api.stackexchange.com/2.3/questions/{question_id}/answers\"\n",
    "    params = {\n",
    "        \"order\": \"desc\",\n",
    "        \"sort\": \"votes\",\n",
    "        \"site\": \"stackoverflow\",\n",
    "        \"filter\": \"withbody\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        answers = response.json().get(\"items\", [])\n",
    "        if answers:\n",
    "            return answers[0][\"body\"] \n",
    "    return \"Brak dostÄ™pnej odpowiedzi.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "169ca1c2-db01-4251-b7be-a09cb063c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stackoverflow_text(html_text):\n",
    "    \"\"\" Usuwa HTML i konwertuje kod na format Markdown \"\"\"\n",
    "    soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "    formatted_text = []\n",
    "\n",
    "    for el in soup.find_all([\"p\", \"pre\", \"code\", \"li\"]):\n",
    "        tag = el.name\n",
    "        text = el.get_text(separator=\" \", strip=True)\n",
    "\n",
    "        if tag == \"pre\":\n",
    "            code = el.find(\"code\")\n",
    "            if code:\n",
    "                text = f\"```python\\n{code.get_text()}\\n```\"\n",
    "            else:\n",
    "                text = f\"```python\\n{text}\\n```\"\n",
    "\n",
    "        elif tag == \"code\" and el.parent.name != \"pre\":\n",
    "            text = f\"`{text}`\"\n",
    "\n",
    "        elif tag == \"li\":\n",
    "            text = f\"- {text}\"\n",
    "\n",
    "        formatted_text.append(text)\n",
    "\n",
    "    return \"\\n\".join(formatted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6c97379-8ade-46ed-8810-c54156bf42b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "all_questions = []\n",
    "\n",
    "for version in python_versions:\n",
    "    questions_loaded = fetch_all_stackoverflow_questions(tag=\"python\", intitle=f\"Python {version}\", max_pages=5, pagesize=30)\n",
    "    all_questions.append({\"questions\": questions_loaded, \"version\": version})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e54d6f14-9895-40a7-86e2-c5540b1e152b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 150\n",
      "40 / 150\n",
      "80 / 150\n",
      "120 / 150\n",
      "Python 3.10 successfully finished\n",
      "0 / 150\n",
      "40 / 150\n",
      "80 / 150\n",
      "120 / 150\n",
      "Python 3.11 successfully finished\n",
      "0 / 123\n",
      "40 / 123\n",
      "80 / 123\n",
      "120 / 123\n",
      "Python 3.12 successfully finished\n",
      "0 / 31\n",
      "Python 3.13 successfully finished\n"
     ]
    }
   ],
   "source": [
    "stackoverflow_data = []\n",
    "\n",
    "for element in all_questions:\n",
    "    questions = element[\"questions\"]\n",
    "    version = element[\"version\"]\n",
    "    \n",
    "    for i, q in enumerate(questions):\n",
    "        question_id = q[\"question_id\"]\n",
    "        best_answer = fetch_best_answer(question_id)\n",
    "\n",
    "        formatted_question = clean_stackoverflow_text(q[\"body\"])\n",
    "        formatted_answer = clean_stackoverflow_text(best_answer)\n",
    "\n",
    "        stackoverflow_data.append({\n",
    "            \"tag\": version,\n",
    "            \"question\": q[\"title\"],\n",
    "            \"question_body\": formatted_question,\n",
    "            \"answer\": formatted_answer,\n",
    "            \"link\": q[\"link\"]\n",
    "        })\n",
    "\n",
    "        if i % 40 == 0:\n",
    "            print(f\"{i} / {len(questions)}\")\n",
    "\n",
    "    print(f\"Python {version} successfully finished\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd9b7c0f-568b-463d-aa88-6e971c57b72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454\n"
     ]
    }
   ],
   "source": [
    "print(len(stackoverflow_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7129d582-70fa-4804-a291-45592fbb9c70",
   "metadata": {},
   "source": [
    "## Stworzenie dynamicznych chunkow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d59cbf8-2dcb-4084-bffa-221b7a0dd831",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647e7c23-6a35-47ca-90bb-d124881cd7d4",
   "metadata": {},
   "source": [
    "### Dokumentacja python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3d75c56-8b24-46a7-befb-0c30ef944467",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPEN_AI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e0d3a26-e9b5-457d-8924-f1e5920cc7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cce36db1-197b-495e-88df-cd1d2a91d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = OPEN_AI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a924cc1-eb78-4800-bee1-f9ee9afec4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8dc2968-311d-4932-abb7-3e683ba39778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.encoding_for_model(\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e63d5a3-65b1-4794-bfc5-9ac1fbf408b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_by_headers(text, max_chunk_size=512, chunk_overlap=100):\n",
    "    \n",
    "    sections = re.split(r'\\n(## [^\\n]+)\\n', text) \n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "\n",
    "    for section in sections:\n",
    "        if section.startswith(\"## \"):\n",
    "            if current_chunk: \n",
    "                chunks.append(current_chunk)\n",
    "            current_chunk = section + \"\\n\" \n",
    "        else:\n",
    "            section_tokens = tokenizer.encode(section)\n",
    "\n",
    "            if len(tokenizer.encode(current_chunk)) + len(section_tokens) <= max_chunk_size:\n",
    "                current_chunk += section + \"\\n\"\n",
    "            else:\n",
    "                for i in range(0, len(section_tokens), max_chunk_size - chunk_overlap):\n",
    "                    chunk_tokens = section_tokens[i:i + max_chunk_size]\n",
    "                    chunk_text = tokenizer.decode(chunk_tokens)\n",
    "                    \n",
    "                    if current_chunk:\n",
    "                        chunks.append(current_chunk)\n",
    "                    \n",
    "                    current_chunk = chunk_text\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eba336a7-da10-40fa-86df-d20e8c5b012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_embedding(text):\n",
    "    response = openai.embeddings.create(\n",
    "        input=[text],\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a95da7-fe51-4993-b27c-a2bf1f292a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_docs_chunks = []\n",
    "\n",
    "for doc in python_docs:\n",
    "    chunks = split_by_headers(doc[\"text\"]) \n",
    "\n",
    "    for chunk in chunks:\n",
    "        python_docs_chunks.append({\n",
    "            \"version\": doc[\"version\"],\n",
    "            \"url\": doc[\"url\"],\n",
    "            \"text\": chunk\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2715eba8-898b-44af-b223-85875cb33750",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(python_docs_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d17888-b19f-4cc9-bfb0-6a893200f58e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d88322-3511-4e42-aa2f-0f961de28c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"backup_tokens.pkl\", \"wb\") as f:\n",
    "    pickle.dump(python_docs_chunks, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8d5b00-38be-427e-a658-f7abb2b83004",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"backup_tokens.pkl\", \"rb\") as f:\n",
    "    python_docs_chunks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c5e752-d273-40ad-a4df-08f3d12b2565",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode(python_docs_chunks[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166a6382-d8a5-47fb-b964-6f31233154d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510b6b3f-b100-466b-baa5-e92cf4164a0c",
   "metadata": {},
   "source": [
    "## ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2174ec16-fc8b-4b52-bddc-44e93dea3ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"chroma_db\")\n",
    "collection = client.get_or_create_collection(name=\"python_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a10486-2098-40f8-b721-17b3c12e8989",
   "metadata": {},
   "source": [
    "### Saving python docs chunks to chroma_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfc8c3f-7bc2-41e7-ae86-3bddeae4c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(python_docs):\n",
    "    python_docs[i]['id'] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3a1b22-d026-4c83-8b01-1206440ea584",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(python_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49de38d5-eb9f-4430-9a6c-acacbf619178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5311a9ac-7f24-4413-be41-65076261305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "python_docs_chunks = []\n",
    "\n",
    "\n",
    "for doc in python_docs:\n",
    "    chunks = split_by_headers(doc[\"text\"]) \n",
    "\n",
    "    for chunk in chunks:\n",
    "        python_docs_chunks.append({\n",
    "            \"version\": doc['version'],\n",
    "            \"url\": doc['url'],\n",
    "            \"text\": chunk,\n",
    "            \"id\": i\n",
    "        })\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f42235f-91a1-432b-9aa0-766cf5f41020",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = max(len(tokenizer.encode(chunk['text'])) for chunk in python_docs_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539b5c18-9258-4394-b95c-5b9e224e029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad873ace-b931-4831-970e-4b3904c9f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(python_docs_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bd3633-35b8-446a-b74d-a15c634661bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(python_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39956dbf-a8bd-4e0e-b50e-d8d7c8538a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(python_docs_chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b8b20c-148f-42ac-a86e-0cda4530bd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_collection(\"python_data\")\n",
    "\n",
    "collection = client.get_or_create_collection(name=\"python_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc5bc15-9132-4a6a-b8b8-86e7f4f02e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_py = 19730\n",
    "\n",
    "while index_py < len(python_docs_chunks):\n",
    "    if \"embedding\" in python_docs_chunks:\n",
    "        continue\n",
    "    doc = python_docs_chunks[index_py]\n",
    "    chunk = doc[\"text\"]\n",
    "    embedding = get_openai_embedding(chunk)\n",
    "    doc_id = f\"{doc['version']}_{doc['id']}\"\n",
    "\n",
    "    collection.add(\n",
    "        ids=[doc_id],\n",
    "        embeddings=[embedding],\n",
    "        metadatas=[{\"version\": doc[\"version\"], \"url\": doc[\"url\"]}],\n",
    "        documents=[chunk]\n",
    "    )\n",
    "\n",
    "    python_docs_chunks[index_py][\"id\"] = doc_id\n",
    "    python_docs_chunks[index_py][\"embedding\"] = embedding\n",
    "    index_py += 1\n",
    "\n",
    "    if index_py % 5 == 0:\n",
    "        print(index_py, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9bf063-36a5-42ec-904a-f53585937b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 19730\n",
    "\n",
    "for kk in range(k, k + 5):\n",
    "    print('embedding' in python_docs_chunks[kk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c758637b-002d-42ec-8410-48afcba505ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tokenizer.encode(python_docs_chunks[32123]['text'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e508b8d3-3ee6-49a4-9242-0956edebb963",
   "metadata": {},
   "source": [
    "### stackoverflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d49066f9-4220-4dda-8e76-c31ba91f04ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_stackoverflow_entry(question, question_body, answer, min_chunk_size=256, max_chunk_size=512, chunk_overlap=100):\n",
    "    \n",
    "    full_text = f\"ðŸ”¹ **Question:** {question}\\n\\n{question_body}\\n\\nðŸ”¹ **Answer:**\\n{answer}\"\n",
    "    tokens = tokenizer.encode(full_text)\n",
    "    chunks = []\n",
    "\n",
    "    if len(tokens) <= min_chunk_size:\n",
    "        return [full_text]\n",
    "    \n",
    "    for i in range(0, len(tokens), max_chunk_size - chunk_overlap):\n",
    "        chunk_tokens = tokens[i:i + max_chunk_size]\n",
    "        chunk_text = tokenizer.decode(chunk_tokens)\n",
    "        chunks.append(chunk_text)\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fde08850-a60d-4722-bfd8-740fddfb0304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing chunks\n"
     ]
    }
   ],
   "source": [
    "stackoverflow_chunks = []\n",
    "index = 0\n",
    "\n",
    "for entry in stackoverflow_data:\n",
    "    chunks = chunk_stackoverflow_entry(\n",
    "        entry[\"question\"], entry[\"question_body\"], entry[\"answer\"]\n",
    "    )\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        stackoverflow_chunks.append({\n",
    "            \"id\": f\"stack_{index}\",\n",
    "            \"question\": entry[\"question\"],\n",
    "            \"text\": chunk,\n",
    "            \"url\": entry[\"link\"],\n",
    "            \"version\": entry[\"tag\"]\n",
    "        })\n",
    "\n",
    "        index += 1\n",
    "\n",
    "print(\"Finished processing chunks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94c1b2f5-ccac-4544-8930-a60636ff02b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02040608010012014016018020022024026028030032034036038040042044046048050052054056058060062064066068070072074076078080082084086088090092094096098010001020104010601080110011201140116011801200122012401260128013001320134013601380140014201440146014801500152015401560"
     ]
    }
   ],
   "source": [
    "index_so = 0\n",
    "\n",
    "while index_so < len(stackoverflow_chunks):\n",
    "    doc = stackoverflow_chunks[index_so]\n",
    "    \n",
    "    if \"embedding\" in doc:\n",
    "        index_so += 1\n",
    "        continue\n",
    "\n",
    "    chunk = doc[\"text\"]\n",
    "    embedding = get_openai_embedding(chunk)\n",
    "    doc_id = f\"stackoverflow_{doc['id']}\"\n",
    "\n",
    "    collection.add(\n",
    "        ids=[doc_id],\n",
    "        embeddings=[embedding],\n",
    "        metadatas=[{\"source\": \"stackoverflow\", \"question\": doc[\"question\"], \"url\": doc[\"url\"], \"version\": doc[\"version\"]}],\n",
    "        documents=[chunk]\n",
    "    )\n",
    "\n",
    "    stackoverflow_chunks[index_so][\"id\"] = doc_id\n",
    "    stackoverflow_chunks[index_so][\"embedding\"] = embedding\n",
    "\n",
    "    if index_so % 20 == 0:\n",
    "        print(index_so, end=\"\")\n",
    "\n",
    "    index_so += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fce15e59-376a-432b-8bc5-226f641d12cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74bb81b6-43da-4b8c-a21e-98785238dcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = chromadb.PersistentClient(path=\"chroma_db\")\n",
    "collection = client.get_or_create_collection(name=\"python_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e1aeef4-5e93-4d2e-b1fa-2cd17a24530e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93929\n"
     ]
    }
   ],
   "source": [
    "print(collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f0a2b03-25ee-43cd-bfeb-662ae89a892e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1412\n"
     ]
    }
   ],
   "source": [
    "all_metadatas = collection.get()[\"metadatas\"]\n",
    "all_ids = collection.get()[\"ids\"]\n",
    "\n",
    "stackoverflow_ids = [doc_id for doc_id, metadata in zip(all_ids, all_metadatas) if metadata.get(\"source\") == \"stackoverflow\"]\n",
    "\n",
    "print(len(stackoverflow_ids))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30f929ae-f7dc-49cd-a8b1-9c656a68c598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: stackoverflow_i-am-using-python-3-12-and-python-3-10-but-python-3-10-not-working-with-msys2_0\n",
      "Add of existing embedding ID: stackoverflow_why-is-apache-tvm-available-for-python-3-10-but-not-python-3-12_0\n",
      "Add of existing embedding ID: stackoverflow_why-does-it-take-longer-to-execute-a-simple-for-loop-in-python-3-12-than-in-pyth_0\n"
     ]
    }
   ],
   "source": [
    "collection.delete(ids=stackoverflow_ids)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
