{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d58e5c0-2079-4736-8e35-949f1e996dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d39e4afb-830c-486d-b764-1f73d32a0de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c831cd1-ad9c-48eb-9974-008f28c887e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPEN_AI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b78fe114-cad3-45b7-8df4-98a28c2c380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = OPEN_AI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35ea7c41-5504-4855-ae5e-3a4d1aade9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_DB_PATH = \"./../data_collecting/chroma_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9244f476-fe73-4db0-99fe-4bc48c21c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "collection = client.get_or_create_collection(name=\"python_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca02c8e8-10bd-4618-ac5b-8ac1653d811f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93929\n"
     ]
    }
   ],
   "source": [
    "print(len(collection.get()[\"metadatas\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54b049e8-128c-4e00-b986-906ee7f59e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07331bbc-207a-4c83-8285-ca736338cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.encoding_for_model(\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "98a2deea-e1e8-46a0-bbd9-9561d2a5e3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_model = \"\"\"\n",
    "    ### Context:\n",
    "    {context}\n",
    "\n",
    "    ### Python version: \n",
    "    {python_version}\n",
    "    \n",
    "    ** Instructions **\n",
    "    - If user asks you to generate code and by using context you cannot do it, then generate it on your own\n",
    "    - If user doesn't ask to generate code and the context does not contain answer for query answet based on your knowledge.\n",
    "    - If the user's question does not specify Python, rephrase it internally as a Python-related question before answering.\n",
    "    - If there is a code in your output explain this code to the user step by step\n",
    "    - Do not answer any other question than about python programming language\n",
    "    - If topic is complex provide summary at the end of your answer\n",
    "    - Do not make up any information\n",
    "    - Provide consise and structured answer\n",
    "\n",
    "    ### Summary of previous conversation:\n",
    "    {summary}\n",
    "\n",
    "    ### Recent conversation history:\n",
    "    \n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "861536d1-51a7-4adf-b3f8-67d79980f662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_embedding(text):\n",
    "    response = openai.embeddings.create(\n",
    "        input=[text],\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def retrieve_documents(query, python_version, top_k=7):\n",
    "    query_embedding = get_openai_embedding(query)\n",
    "\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=top_k,\n",
    "        where={\"version\": python_version}\n",
    "    )\n",
    "\n",
    "    return results[\"documents\"][0] if \"documents\" in results and results[\"documents\"] else []\n",
    "\n",
    "def generate_response(query, retrieved_docs, python_version):\n",
    "    context = \"\\n\\n\".join(retrieved_docs)\n",
    "    \n",
    "    prompt = prompt_model.format(context = context,query = query,python_version = python_version)\n",
    "    client = openai.Client()\n",
    "    response = client.chat.completions.create(\n",
    "        model=chat_model,\n",
    "        temperature=0.3,\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are python expert and you provide answer only based on given context.\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ddb8c10-5b57-4b65-87c6-e9579c8e024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryBufferMemory:\n",
    "    def __init__(self, max_tokens=3500, window_size=5, model=\"gpt4o-mini\"):\n",
    "        self.history = []\n",
    "        self.summary = \"\"\n",
    "        self.max_tokens = max_tokens\n",
    "        self.window_size = window_size\n",
    "        self.model = model\n",
    "\n",
    "    def add_interaction(self, query, assistant_output):\n",
    "        self.history.append({\"user\": query, \"assistant\": assistant_output})\n",
    "        if self.get_token_count() > self.max_tokens:\n",
    "            self.summarize_history()\n",
    "\n",
    "    def get_token_count(self):\n",
    "        text = \" \".join([f\"{h['user']} {h['assistant']}\" for h in self.history])\n",
    "        return len(tokenizer.encode(text))\n",
    "\n",
    "    def summarize_history(self):\n",
    "        conversation_text = \"\\n\".join(\n",
    "            f\"User: {h['user']}\\nAssistant: {h['assistant']}\" for h in self.history[:-self.window_size]\n",
    "        )\n",
    "\n",
    "        summarization_prompt = f\"\"\"\n",
    "        Your task is to summarize the following conversation between a user and an assistant.\n",
    "        - Focus ONLY on key technical details (technologies, libraries, coding languages, user's project specifics).\n",
    "        - Omit greetings, general questions, or small talk.\n",
    "        - Limit your summary to 7-10 concise sentences.\n",
    "\n",
    "        Conversation:\n",
    "        {conversation_text}\n",
    "\n",
    "        Summary:\n",
    "        \"\"\"\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": summarization_prompt}],\n",
    "            temperature=0.2\n",
    "        )\n",
    "\n",
    "        self.summary = response.choices[0].message.content\n",
    "\n",
    "        self.history = self.history[-self.window_size:]\n",
    "\n",
    "    def get_prompt(self, query, context, python_version=\"3.10\"):\n",
    "        prompt = prompt_model.format(context = context,query = query,python_version = python_version, summary=self.summary)\n",
    "\n",
    "        for msg in self.history:\n",
    "            prompt += f\"User: {msg['user']}\\nAssistant: {msg['assistant']}\\n\"\n",
    "\n",
    "        prompt += f\"User: {query}\\nAssistant:\"\n",
    "\n",
    "        return prompt\n",
    "\n",
    "\n",
    "def generate_with_memory(query, context, memory, python_version=\"3.11\"):\n",
    "    context = \"\\n\\n\".join(context)\n",
    "    client = openai.Client()\n",
    "    prompt = memory.get_prompt(query, context, python_version)\n",
    "    print(prompt)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=chat_model,\n",
    "        temperature=0.3,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are python expert and you provide answer only based on given context.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    assistant_response = response.choices[0].message.content\n",
    "    memory.add_interaction(query, assistant_output=assistant_response)\n",
    "\n",
    "    return assistant_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e91f9c68-d268-4b3e-8a47-980dc37965cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m retrieved_docs \u001b[38;5;241m=\u001b[39m retrieve_documents(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow can i open file?\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.10\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m answer \u001b[38;5;241m=\u001b[39m generate_response(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow can i open file?\u001b[39m\u001b[38;5;124m\"\u001b[39m, retrieved_docs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.10\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[41], line 22\u001b[0m, in \u001b[0;36mgenerate_response\u001b[1;34m(query, retrieved_docs, python_version)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_response\u001b[39m(query, retrieved_docs, python_version):\n\u001b[0;32m     20\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(retrieved_docs)\n\u001b[1;32m---> 22\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m prompt_model\u001b[38;5;241m.\u001b[39mformat(context \u001b[38;5;241m=\u001b[39m context,query \u001b[38;5;241m=\u001b[39m query,python_version \u001b[38;5;241m=\u001b[39m python_version)\n\u001b[0;32m     23\u001b[0m     client \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mClient()\n\u001b[0;32m     24\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     25\u001b[0m         model\u001b[38;5;241m=\u001b[39mchat_model,\n\u001b[0;32m     26\u001b[0m         temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m,\n\u001b[0;32m     27\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are python expert and you provide answer only based on given context.\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m     28\u001b[0m                   {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}]\n\u001b[0;32m     29\u001b[0m     )\n",
      "\u001b[1;31mKeyError\u001b[0m: 'summary'"
     ]
    }
   ],
   "source": [
    "retrieved_docs = retrieve_documents(\"How can i open file?\", \"3.10\", 8)\n",
    "answer = generate_response(\"How can i open file?\", retrieved_docs, \"3.10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae459b15-91fe-4c7b-8915-004d3a3086f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To open a file in Python, you can use the built-in `open()` function. Here’s a simple example of how to use it:\\n\\n```python\\nfile = open(\\'example.txt\\', \\'r\\')\\n```\\n\\n### Explanation:\\n1. **`open()` Function**: This function is used to open a file. It takes two main arguments:\\n   - The first argument is the name of the file you want to open (in this case, `\\'example.txt\\'`).\\n   - The second argument is the mode in which you want to open the file. In this example, `\\'r\\'` stands for \"read\" mode, which means you want to read the contents of the file.\\n\\n2. **File Object**: The `open()` function returns a file object, which you can use to read from or write to the file.\\n\\n### Summary:\\nTo open a file in Python, use the `open()` function with the appropriate file name and mode. In this example, we opened a file named `\\'example.txt\\'` in read mode.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f830c05f-519c-4c79-b361-3f94750de5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1f91a749-1548-4c6f-984c-7c6e98e15562",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SummaryBufferMemory(max_tokens=2000, window_size=5, model=chat_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "80bb74f7-cd84-42d7-8762-2cb3b8efd402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ### Context:\n",
      "    ## Functions and decorators Â¶\n",
      "\n",
      "\n",
      "## Patch Decorators Â¶\n",
      "\n",
      "\n",
      "## Nesting Patch Decorators Â¶\n",
      "\n",
      "\n",
      "\n",
      "If you want several patches in place for multiple test methods the obvious way\n",
      "is to apply the patch decorators to every method. This can feel like unnecessary\n",
      "repetition. For Python 2.6 or more recent you can use patch() (in all its\n",
      "various forms) as a class decorator. This applies the patches to all test\n",
      "methods on the class. A test method is identified by methods whose names start\n",
      "with test :\n",
      "`patch()`\n",
      "`patch()`\n",
      "`test`\n",
      "`test`\n",
      ">>> @patch ( 'mymodule.SomeClass' ) ... class MyTest ( unittest . TestCase ): ... ... def test_one ( self , MockSomeClass ): ... self . assertIs ( mymodule . SomeClass , MockSomeClass ) ... ... def test_two ( self , MockSomeClass ): ... self . assertIs ( mymodule . SomeClass , MockSomeClass ) ... ... def not_a_test ( self ): ... return 'something' ... >>> MyTest ( 'test_one' ) . test_one () >>> MyTest ( 'test_two' ) . test_two () >>> MyTest ( 'test_two' ) . not_a_test () 'something'\n",
      ">>> @patch ( 'mymodule.SomeClass' ) ... class MyTest ( unittest . TestCase ): ... ... def test_one ( self , MockSomeClass ): ... self . assertIs ( mymodule . SomeClass , MockSomeClass ) ... ... def test_two ( self , MockSomeClass ): ... self . assertIs ( mymodule . SomeClass , MockSomeClass ) ... ... def not_a_test ( self ): ... return 'something' ... >>> MyTest ( 'test_one' ) . test_one () >>> MyTest ( 'test_two' ) . test_two () >>> MyTest ( 'test_two' ) . not_a_test () 'something'\n",
      "```python\n",
      ">>> @patch ( 'mymodule.SomeClass' ) ... class MyTest ( unittest . TestCase ): ... ... def test_one ( self , MockSomeClass ): ... self . assertIs ( mymodule . SomeClass , MockSomeClass ) ... ... def test_two ( self , MockSomeClass ): ... self . assertIs ( mymodule . SomeClass , MockSomeClass ) ... ... def not_a_test ( self ): ... return 'something' ... >>> MyTest ( 'test_one' ) . test_one () >>> MyTest ( 'test_two' ) . test_two () >>> MyTest ( 'test_two' ) . not_a_test () 'something'\n",
      "\n",
      "\n",
      " you want several patches in place for multiple test methods the obvious way\n",
      "is to apply the patch decorators to every method. This can feel like unnecessary\n",
      "repetition. For Python 2.6 or more recent you can use patch() (in all its\n",
      "various forms) as a class decorator. This applies the patches to all test\n",
      "methods on the class. A test method is identified by methods whose names start\n",
      "with test : >>> @patch ( 'mymodule.SomeClass' ) ... class MyTest ( unittest . TestCase ): ... ... def test_one ( self , MockSomeClass ): ... self . assertIs ( mymodule . SomeClass , MockSomeClass ) ... ... def test_two ( self , MockSomeClass ): ... self . assertIs ( mymodule . SomeClass , MockSomeClass ) ... ... def not_a_test ( self ): ... return 'something' ... >>> MyTest ( 'test_one' ) . test_one () >>> MyTest ( 'test_two' ) . test_two () >>> MyTest ( 'test_two' ) . not_a_test () 'something' An alternative way of managing patches is to use the patch methods: start and stop .\n",
      "These allow you to move the patching into your setUp and tearDown methods. >>> class MyTest ( unittest . TestCase ): ... def setUp ( self ): ... self . patcher = patch ( 'mymodule.foo' ) ... self . mock_foo = self . patcher . start () ... ... def test_foo ( self ): ... self . assertIs ( mymodule . foo , self . mock_foo ) ... ... def tearDown ( self ): ... self . patcher . stop () ... >>> MyTest ( 'test_foo' ) . run () If you use this technique you must ensure that the patching is âundoneâ by\n",
      "calling stop . This can be fiddlier than you might think, because if an\n",
      "exception is raised in the setUp then tearDown is not called. unittest.TestCase.addCleanup() makes this easier: >>> class MyTest ( unittest . TestCase ): ... def setUp ( self ): ... patcher = patch ( 'mymodule.foo' ) ... self . addCleanup ( patcher . stop ) ... self . mock_foo = patcher . start () ... ... def test_foo ( self ): ... self . assertIs ( mymodule . foo , self . mock_foo ) ... >>> MyTest ( 'test_foo' ) . run () Mocking Unbound Methods\n",
      "\n",
      "## Python Interface Â¶\n",
      "\n",
      "\n",
      " () A nice pattern is to actually decorate test methods themselves: >>> class MyTest ( unittest . TestCase ): ... @patch . object ( SomeClass , 'attribute' , sentinel . attribute ) ... def test_something ( self ): ... self . assertEqual ( SomeClass . attribute , sentinel . attribute ) ... >>> original = SomeClass . attribute >>> MyTest ( 'test_something' ) . test_something () >>> assert SomeClass . attribute == original If you want to patch with a Mock, you can use patch() with only one argument\n",
      "(or patch.object() with two arguments). The mock will be created for you and\n",
      "passed into the test function / method: >>> class MyTest ( unittest . TestCase ): ... @patch . object ( SomeClass , 'static_method' ) ... def test_something ( self , mock_method ): ... SomeClass . static_method () ... mock_method . assert_called_with () ... >>> MyTest ( 'test_something' ) . test_something () You can stack up multiple patch decorators using this pattern: >>> class MyTest ( unittest . TestCase ): ... @patch ( 'package.module.ClassName1' ) ... @patch ( 'package.module.ClassName2' ) ... def test_something ( self , MockClass2 , MockClass1 ): ... self . assertIs ( package . module . ClassName1 , MockClass1 ) ... self . assertIs ( package . module . ClassName2 , MockClass2 ) ... >>> MyTest ( 'test_something' ) . test_something () When you nest patch decorators the mocks are passed in to the decorated\n",
      "function in the same order they applied (the normal Python order that\n",
      "decorators are applied). This means from the bottom up, so in the example\n",
      "above the mock for test_module.ClassName2 is passed in first. There is also patch.dict() for setting values in a dictionary just\n",
      "during a scope and restoring the dictionary to its original state when the test\n",
      "ends: >>> foo = { 'key' : 'value' } >>> original = foo . copy () >>> with patch . dict ( foo , { 'newkey' : 'newvalue' }, clear = True ): ... assert foo == { 'newkey' : 'newvalue' } ... >>> assert foo == original patch , patch.object and patch.dict can all be used as context managers. Where you use patch() to create a mock for you, you can get a reference to the\n",
      "mock using the âasâ form of the with\n",
      "\n",
      "    ### Python version: \n",
      "    3.10\n",
      "    \n",
      "    ** Instructions **\n",
      "    - If user asks you to generate code and by using context you cannot do it, then generate it on your own\n",
      "    - If user doesn't ask to generate code and the context does not contain answer for query answet based on your knowledge.\n",
      "    - If the user's question does not specify Python, rephrase it internally as a Python-related question before answering.\n",
      "    - If there is a code in your output explain this code to the user step by step\n",
      "    - Do not answer any other question than about python programming language\n",
      "    - If topic is complex provide summary at the end of your answer\n",
      "    - Do not make up any information\n",
      "    - Provide consise and structured answer\n",
      "\n",
      "    ### Summary of previous conversation:\n",
      "    \n",
      "\n",
      "    ### Recent conversation history:\n",
      "    \n",
      "    User: How to implement decorators in python?\n",
      "Assistant:\n"
     ]
    }
   ],
   "source": [
    "query = \"How to implement decorators in python?\"\n",
    "retrieved_docs = retrieve_documents(query, \"3.10\", top_k=7)\n",
    "\n",
    "answer = generate_with_memory(query, retrieved_docs, memory, \"3.10\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "880243d6-f30b-4156-94eb-bb5b9fb8b091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To implement decorators in Python, you typically define a function that takes another function as an argument and returns a new function that usually extends or modifies the behavior of the original function. Here’s a step-by-step explanation:\\n\\n1. **Define the Decorator Function**: Create a function that takes a function as an argument.\\n2. **Define an Inner Function**: Inside the decorator, define a nested function that will wrap the original function.\\n3. **Call the Original Function**: Inside the inner function, you can call the original function and add any additional behavior before or after this call.\\n4. **Return the Inner Function**: The outer function should return the inner function.\\n\\nHere’s a simple example:\\n\\n```python\\ndef my_decorator(func):\\n    def wrapper():\\n        print(\"Something is happening before the function is called.\")\\n        func()\\n        print(\"Something is happening after the function is called.\")\\n    return wrapper\\n\\n@my_decorator\\ndef say_hello():\\n    print(\"Hello!\")\\n\\nsay_hello()\\n```\\n\\n### Explanation of the Code:\\n- `my_decorator`: This is the decorator function that takes another function `func` as an argument.\\n- `wrapper`: This is the inner function that adds behavior before and after calling `func`.\\n- `@my_decorator`: This is the decorator syntax that applies `my_decorator` to the `say_hello` function.\\n- When `say_hello()` is called, it actually calls `wrapper()`, which includes additional print statements before and after the original `say_hello` function\\'s behavior.\\n\\n### Summary:\\nDecorators in Python are a powerful way to modify or extend the behavior of functions. They are defined as functions that wrap other functions and can be applied using the `@decorator_name` syntax.'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "681bf87c-82f6-444f-8790-35bfe7f61c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ### Context:\n",
      "    ## ANY Â¶\n",
      "\n",
      "\n",
      "## help Â¶\n",
      "\n",
      "\n",
      "`\n",
      "\n",
      "\n",
      "\n",
      "()\n",
      "\n",
      "\n",
      "\n",
      "\"`\n",
      "\n",
      "\n",
      "\n",
      "## Babyl Â¶\n",
      "\n",
      "\n",
      "## MH Â¶\n",
      "\n",
      "\n",
      "    ### Python version: \n",
      "    3.10\n",
      "    \n",
      "    ** Instructions **\n",
      "    - If user asks you to generate code and by using context you cannot do it, then generate it on your own\n",
      "    - If user doesn't ask to generate code and the context does not contain answer for query answet based on your knowledge.\n",
      "    - If the user's question does not specify Python, rephrase it internally as a Python-related question before answering.\n",
      "    - If there is a code in your output explain this code to the user step by step\n",
      "    - Do not answer any other question than about python programming language\n",
      "    - If topic is complex provide summary at the end of your answer\n",
      "    - Do not make up any information\n",
      "    - Provide consise and structured answer\n",
      "\n",
      "    ### Summary of previous conversation:\n",
      "    \n",
      "\n",
      "    ### Recent conversation history:\n",
      "    \n",
      "    User: How to implement decorators in python?\n",
      "Assistant: To implement decorators in Python, you typically define a function that takes another function as an argument and returns a new function that usually extends or modifies the behavior of the original function. Here’s a step-by-step explanation:\n",
      "\n",
      "1. **Define the Decorator Function**: Create a function that takes a function as an argument.\n",
      "2. **Define an Inner Function**: Inside the decorator, define a nested function that will wrap the original function.\n",
      "3. **Call the Original Function**: Inside the inner function, you can call the original function and add any additional behavior before or after this call.\n",
      "4. **Return the Inner Function**: The outer function should return the inner function.\n",
      "\n",
      "Here’s a simple example:\n",
      "\n",
      "```python\n",
      "def my_decorator(func):\n",
      "    def wrapper():\n",
      "        print(\"Something is happening before the function is called.\")\n",
      "        func()\n",
      "        print(\"Something is happening after the function is called.\")\n",
      "    return wrapper\n",
      "\n",
      "@my_decorator\n",
      "def say_hello():\n",
      "    print(\"Hello!\")\n",
      "\n",
      "say_hello()\n",
      "```\n",
      "\n",
      "### Explanation of the Code:\n",
      "- `my_decorator`: This is the decorator function that takes another function `func` as an argument.\n",
      "- `wrapper`: This is the inner function that adds behavior before and after calling `func`.\n",
      "- `@my_decorator`: This is the decorator syntax that applies `my_decorator` to the `say_hello` function.\n",
      "- When `say_hello()` is called, it actually calls `wrapper()`, which includes additional print statements before and after the original `say_hello` function's behavior.\n",
      "\n",
      "### Summary:\n",
      "Decorators in Python are a powerful way to modify or extend the behavior of functions. They are defined as functions that wrap other functions and can be applied using the `@decorator_name` syntax.\n",
      "User: How to implement decorators?\n",
      "Assistant: To implement decorators in Python, you typically follow these steps:\n",
      "\n",
      "1. **Define the Decorator Function**: Create a function that takes another function as an argument.\n",
      "2. **Define an Inner Function**: Inside the decorator, define a nested function that will wrap the original function.\n",
      "3. **Call the Original Function**: Inside the inner function, you can call the original function and add any additional behavior before or after this call.\n",
      "4. **Return the Inner Function**: The outer function should return the inner function.\n",
      "\n",
      "Here’s a simple example:\n",
      "\n",
      "```python\n",
      "def my_decorator(func):\n",
      "    def wrapper():\n",
      "        print(\"Something is happening before the function is called.\")\n",
      "        func()\n",
      "        print(\"Something is happening after the function is called.\")\n",
      "    return wrapper\n",
      "\n",
      "@my_decorator\n",
      "def say_hello():\n",
      "    print(\"Hello!\")\n",
      "\n",
      "say_hello()\n",
      "```\n",
      "\n",
      "### Explanation of the Code:\n",
      "- **`my_decorator`**: This is the decorator function that takes another function `func` as an argument.\n",
      "- **`wrapper`**: This is the inner function that adds behavior before and after calling `func`.\n",
      "- **`@my_decorator`**: This is the decorator syntax that applies `my_decorator` to the `say_hello` function.\n",
      "- When `say_hello()` is called, it actually calls `wrapper()`, which includes additional print statements before and after the original `say_hello` function's behavior.\n",
      "\n",
      "### Summary:\n",
      "Decorators in Python are a powerful way to modify or extend the behavior of functions. They are defined as functions that wrap other functions and can be applied using the `@decorator_name` syntax.\n",
      "User: What is wrong with you?\n",
      "Assistant:\n"
     ]
    }
   ],
   "source": [
    "query = \"What is wrong with you?\"\n",
    "retrieved_docs = retrieve_documents(query, \"3.10\", top_k=7)\n",
    "\n",
    "answer = generate_with_memory(query, retrieved_docs, memory, \"3.10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5ceacd6e-460c-46bd-981c-60d498b6d224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm here to assist you with Python programming questions. If you have a specific query or need help with Python code, please let me know!\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
