{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d58e5c0-2079-4736-8e35-949f1e996dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d39e4afb-830c-486d-b764-1f73d32a0de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c831cd1-ad9c-48eb-9974-008f28c887e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPEN_AI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b78fe114-cad3-45b7-8df4-98a28c2c380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = OPEN_AI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35ea7c41-5504-4855-ae5e-3a4d1aade9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_DB_PATH = \"./../data_collecting/chroma_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9244f476-fe73-4db0-99fe-4bc48c21c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "collection = client.get_or_create_collection(name=\"python_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54b049e8-128c-4e00-b986-906ee7f59e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07331bbc-207a-4c83-8285-ca736338cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.encoding_for_model(\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98a2deea-e1e8-46a0-bbd9-9561d2a5e3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_model = \"\"\"\n",
    "    ### Context:\n",
    "    {context}\n",
    "\n",
    "    ### Python version: \n",
    "    {python_version}\n",
    "    \n",
    "    ** Instructions **\n",
    "    - If user asks you to generate code and by using context you cannot do it, then generate it on your own\n",
    "    - If user doesn't ask to generate code and the context does not contain answer for query answet based on your knowledge.\n",
    "    - If the user's question does not specify Python, rephrase it internally as a Python-related question before answering.\n",
    "    - If there is a code in your output explain this code to the user step by step\n",
    "    - Do not answer any other question than about python programming language\n",
    "    - If topic is complex provide summary at the end of your answer\n",
    "    - Do not make up any information\n",
    "    - Provide consise and structured answer\n",
    "\n",
    "    ### Summary of previous conversation:\n",
    "    {summary}\n",
    "\n",
    "    ### Recent conversation history:\n",
    "    \n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "861536d1-51a7-4adf-b3f8-67d79980f662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_embedding(text):\n",
    "    response = openai.embeddings.create(\n",
    "        input=[text],\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def retrieve_documents(query, python_version, top_k=7):\n",
    "    query_embedding = get_openai_embedding(query)\n",
    "\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=top_k,\n",
    "        where={\"version\": python_version}\n",
    "    )\n",
    "\n",
    "    return results[\"documents\"][0] if \"documents\" in results and results[\"documents\"] else []\n",
    "\n",
    "def generate_response(query, retrieved_docs, python_version):\n",
    "    context = \"\\n\\n\".join(retrieved_docs)\n",
    "    \n",
    "    prompt = prompt_model.format(context = context,query = query,python_version = python_version)\n",
    "    client = openai.Client()\n",
    "    response = client.chat.completions.create(\n",
    "        model=chat_model,\n",
    "        temperature=0.3,\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are python expert and you provide answer only based on given context.\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ddb8c10-5b57-4b65-87c6-e9579c8e024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryBufferMemory:\n",
    "    def __init__(self, max_tokens=3500, window_size=5, model=\"gpt4o-mini\"):\n",
    "        self.history = []\n",
    "        self.summary = \"\"\n",
    "        self.max_tokens = max_tokens\n",
    "        self.window_size = window_size\n",
    "        self.model = model\n",
    "\n",
    "    def add_interaction(self, query, assistant_output):\n",
    "        self.history.append({\"user\": query, \"assistant\": assistant_output})\n",
    "        if self.get_token_count() > self.max_tokens:\n",
    "            self.summarize_history()\n",
    "\n",
    "    def get_token_count(self):\n",
    "        text = \" \".join([f\"{h['user']} {h['assistant']}\" for h in self.history])\n",
    "        return len(tokenizer.encode(text))\n",
    "\n",
    "    def summarize_history(self):\n",
    "        conversation_text = \"\\n\".join(\n",
    "            f\"User: {h['user']}\\nAssistant: {h['assistant']}\" for h in self.history[:-self.window_size]\n",
    "        )\n",
    "\n",
    "        summarization_prompt = f\"\"\"\n",
    "        Your task is to summarize the following conversation between a user and an assistant.\n",
    "        - Focus ONLY on key technical details (technologies, libraries, coding languages, user's project specifics).\n",
    "        - Omit greetings, general questions, or small talk.\n",
    "        - Limit your summary to 7-10 concise sentences.\n",
    "\n",
    "        Conversation:\n",
    "        {conversation_text}\n",
    "\n",
    "        Summary:\n",
    "        \"\"\"\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": summarization_prompt}],\n",
    "            temperature=0.2\n",
    "        )\n",
    "\n",
    "        self.summary = response.choices[0].message.content\n",
    "\n",
    "        self.history = self.history[-self.window_size:]\n",
    "\n",
    "    def get_prompt(self, query, context, python_version=\"3.10\"):\n",
    "        prompt = prompt_model.format(context = context,query = query,python_version = python_version, summary=self.summary)\n",
    "\n",
    "        for msg in self.history:\n",
    "            prompt += f\"User: {msg['user']}\\nAssistant: {msg['assistant']}\\n\"\n",
    "\n",
    "        prompt += f\"User: {query}\\nAssistant:\"\n",
    "\n",
    "        return prompt\n",
    "\n",
    "\n",
    "def generate_with_memory(query, context, memory, python_version=\"3.11\"):\n",
    "    context = \"\\n\\n\".join(context)\n",
    "    client = openai.Client()\n",
    "    prompt = memory.get_prompt(query, context, python_version)\n",
    "    print(prompt)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=chat_model,\n",
    "        temperature=0.3,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are python expert and you provide answer only based on given context.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    assistant_response = response.choices[0].message.content\n",
    "    memory.add_interaction(query, assistant_output=assistant_response)\n",
    "\n",
    "    return assistant_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e91f9c68-d268-4b3e-8a47-980dc37965cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m retrieved_docs \u001b[38;5;241m=\u001b[39m retrieve_documents(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow can i open file?\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.10\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m answer \u001b[38;5;241m=\u001b[39m generate_response(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow can i open file?\u001b[39m\u001b[38;5;124m\"\u001b[39m, retrieved_docs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.10\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[41], line 22\u001b[0m, in \u001b[0;36mgenerate_response\u001b[1;34m(query, retrieved_docs, python_version)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_response\u001b[39m(query, retrieved_docs, python_version):\n\u001b[0;32m     20\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(retrieved_docs)\n\u001b[1;32m---> 22\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m prompt_model\u001b[38;5;241m.\u001b[39mformat(context \u001b[38;5;241m=\u001b[39m context,query \u001b[38;5;241m=\u001b[39m query,python_version \u001b[38;5;241m=\u001b[39m python_version)\n\u001b[0;32m     23\u001b[0m     client \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mClient()\n\u001b[0;32m     24\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     25\u001b[0m         model\u001b[38;5;241m=\u001b[39mchat_model,\n\u001b[0;32m     26\u001b[0m         temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m,\n\u001b[0;32m     27\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are python expert and you provide answer only based on given context.\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m     28\u001b[0m                   {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}]\n\u001b[0;32m     29\u001b[0m     )\n",
      "\u001b[1;31mKeyError\u001b[0m: 'summary'"
     ]
    }
   ],
   "source": [
    "retrieved_docs = retrieve_documents(\"How can i open file?\", \"3.10\", 8)\n",
    "answer = generate_response(\"How can i open file?\", retrieved_docs, \"3.10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae459b15-91fe-4c7b-8915-004d3a3086f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To open a file in Python, you can use the built-in `open()` function. Here’s a simple example of how to use it:\\n\\n```python\\nfile = open(\\'example.txt\\', \\'r\\')\\n```\\n\\n### Explanation:\\n1. **`open()` Function**: This function is used to open a file. It takes two main arguments:\\n   - The first argument is the name of the file you want to open (in this case, `\\'example.txt\\'`).\\n   - The second argument is the mode in which you want to open the file. In this example, `\\'r\\'` stands for \"read\" mode, which means you want to read the contents of the file.\\n\\n2. **File Object**: The `open()` function returns a file object, which you can use to read from or write to the file.\\n\\n### Summary:\\nTo open a file in Python, use the `open()` function with the appropriate file name and mode. In this example, we opened a file named `\\'example.txt\\'` in read mode.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f830c05f-519c-4c79-b361-3f94750de5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1f91a749-1548-4c6f-984c-7c6e98e15562",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SummaryBufferMemory(max_tokens=2000, window_size=5, model=chat_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "80bb74f7-cd84-42d7-8762-2cb3b8efd402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ### Context:\n",
      "    ## Functions and decorators Â¶\n",
      "\n",
      "\n",
      "## Patch Decorators Â¶\n",
      "\n",
      "\n",
      "## Nesting Patch Decorators Â¶\n",
      "\n",
      "\n",
      "\n",
      "If you want several patches in place for multiple test methods the obvious way\n",
      "is to apply the patch decorators to every method. This can feel like unnecessary\n",
      "repetition. For Python 2.6 or more recent you can use patch() (in all its\n",
      "various forms) as a class decorator. This applies the patches to all test\n",
      "methods on the class. A test method is identified by methods whose names start\n",
      "with test :\n",
      "`patch()`\n",
      "`patch()`\n",
      "`test`\n",
      "`test`\n",
      ">>> @patch ( 'mymodule.SomeClass' ) ... class MyTest ( unittest . TestCase ): ... ... def test_one ( self , MockSomeClass ): ... self . assertIs ( mymodule . SomeClass , MockSomeClass ) ... ... def test_two ( self , MockSomeClass ): ... self . assertIs ( mymodule . SomeClass , MockSomeClass ) ... ... def not_a_test ( self ): ... return 'something' ... >>> MyTest ( 'test_one' ) . test_one () >>> MyTest ( 'test_two' ) . test_two () >>> MyTest ( 'test_two' ) . not_a_test () 'something'\n",
      ">>> @patch ( 'mymodule.SomeClass' ) ... class MyTest ( unittest . TestCase ): ... ... def test_one ( self , MockSomeClass ): ... self . assertIs ( mymodule . SomeClass , MockSomeClass ) ... ... def test_two ( self , MockSomeClass ): ... self . assertIs ( mymodule . SomeClass , MockSomeClass ) ... ... def not_a_test ( self ): ... return 'something' ... >>> MyTest ( 'test_one' ) . test_one () >>> MyTest ( 'test_two' ) . test_two () >>> MyTest ( 'test_two' ) . not_a_test () 'something'\n",
      "```python\n",
      ">>> @patch ( 'mymodule.SomeClass' ) ... class MyTest ( unittest . TestCase ): ... ... def test_one ( self , MockSomeClass ): ... self . assertIs ( mymodule . SomeClass , MockSomeClass ) ... ... def test_two ( self , MockSomeClass ): ... self . assertIs ( mymodule . SomeClass , MockSomeClass ) ... ... def not_a_test ( self ): ... return 'something' ... >>> MyTest ( 'test_one' ) . test_one () >>> MyTest ( 'test_two' ) . test_two () >>> MyTest ( 'test_two' ) . not_a_test () 'something'\n",
      "\n",
      "\n",
      " you want several patches in place for multiple test methods the obvious way\n",
      "is to apply the patch decorators to every method. This can feel like unnecessary\n",
      "repetition. For Python 2.6 or more recent you can use patch() (in all its\n",
      "various forms) as a class decorator. This applies the patches to all test\n",
      "methods on the class. A test method is identified by methods whose names start\n",
      "with test : >>> @patch ( 'mymodule.SomeClass' ) ... class MyTest ( unittest . TestCase ): ... ... def test_one ( self , MockSomeClass ): ... self . assertIs ( mymodule . SomeClass , MockSomeClass ) ... ... def test_two ( self , MockSomeClass ): ... self . assertIs ( mymodule . SomeClass , MockSomeClass ) ... ... def not_a_test ( self ): ... return 'something' ... >>> MyTest ( 'test_one' ) . test_one () >>> MyTest ( 'test_two' ) . test_two () >>> MyTest ( 'test_two' ) . not_a_test () 'something' An alternative way of managing patches is to use the patch methods: start and stop .\n",
      "These allow you to move the patching into your setUp and tearDown methods. >>> class MyTest ( unittest . TestCase ): ... def setUp ( self ): ... self . patcher = patch ( 'mymodule.foo' ) ... self . mock_foo = self . patcher . start () ... ... def test_foo ( self ): ... self . assertIs ( mymodule . foo , self . mock_foo ) ... ... def tearDown ( self ): ... self . patcher . stop () ... >>> MyTest ( 'test_foo' ) . run () If you use this technique you must ensure that the patching is âundoneâ by\n",
      "calling stop . This can be fiddlier than you might think, because if an\n",
      "exception is raised in the setUp then tearDown is not called. unittest.TestCase.addCleanup() makes this easier: >>> class MyTest ( unittest . TestCase ): ... def setUp ( self ): ... patcher = patch ( 'mymodule.foo' ) ... self . addCleanup ( patcher . stop ) ... self . mock_foo = patcher . start () ... ... def test_foo ( self ): ... self . assertIs ( mymodule . foo , self . mock_foo ) ... >>> MyTest ( 'test_foo' ) . run () Mocking Unbound Methods\n",
      "\n",
      "## Python Interface Â¶\n",
      "\n",
      "\n",
      " () A nice pattern is to actually decorate test methods themselves: >>> class MyTest ( unittest . TestCase ): ... @patch . object ( SomeClass , 'attribute' , sentinel . attribute ) ... def test_something ( self ): ... self . assertEqual ( SomeClass . attribute , sentinel . attribute ) ... >>> original = SomeClass . attribute >>> MyTest ( 'test_something' ) . test_something () >>> assert SomeClass . attribute == original If you want to patch with a Mock, you can use patch() with only one argument\n",
      "(or patch.object() with two arguments). The mock will be created for you and\n",
      "passed into the test function / method: >>> class MyTest ( unittest . TestCase ): ... @patch . object ( SomeClass , 'static_method' ) ... def test_something ( self , mock_method ): ... SomeClass . static_method () ... mock_method . assert_called_with () ... >>> MyTest ( 'test_something' ) . test_something () You can stack up multiple patch decorators using this pattern: >>> class MyTest ( unittest . TestCase ): ... @patch ( 'package.module.ClassName1' ) ... @patch ( 'package.module.ClassName2' ) ... def test_something ( self , MockClass2 , MockClass1 ): ... self . assertIs ( package . module . ClassName1 , MockClass1 ) ... self . assertIs ( package . module . ClassName2 , MockClass2 ) ... >>> MyTest ( 'test_something' ) . test_something () When you nest patch decorators the mocks are passed in to the decorated\n",
      "function in the same order they applied (the normal Python order that\n",
      "decorators are applied). This means from the bottom up, so in the example\n",
      "above the mock for test_module.ClassName2 is passed in first. There is also patch.dict() for setting values in a dictionary just\n",
      "during a scope and restoring the dictionary to its original state when the test\n",
      "ends: >>> foo = { 'key' : 'value' } >>> original = foo . copy () >>> with patch . dict ( foo , { 'newkey' : 'newvalue' }, clear = True ): ... assert foo == { 'newkey' : 'newvalue' } ... >>> assert foo == original patch , patch.object and patch.dict can all be used as context managers. Where you use patch() to create a mock for you, you can get a reference to the\n",
      "mock using the âasâ form of the with\n",
      "\n",
      "\n",
      "constructors.\n",
      "`classmethod()`\n",
      "`classmethod()`\n",
      "Like all decorators, it is also possible to call staticmethod as\n",
      "a regular function and do something with its result.  This is needed\n",
      "in some cases where you need a reference to a function from a class\n",
      "body and you want to avoid the automatic transformation to instance\n",
      "method.  For these cases, use this idiom:\n",
      "`staticmethod`\n",
      "`staticmethod`\n",
      "def regular_function (): ... class C : method = staticmethod ( regular_function )\n",
      "def regular_function (): ... class C : method = staticmethod ( regular_function )\n",
      "```python\n",
      "def regular_function (): ... class C : method = staticmethod ( regular_function )\n",
      "```\n",
      "\n",
      "def\n",
      "regular_function\n",
      "():\n",
      "...\n",
      "class\n",
      "C\n",
      ":\n",
      "method\n",
      "=\n",
      "staticmethod\n",
      "(\n",
      "regular_function\n",
      ")\n",
      "For more information on static methods, see The standard type hierarchy .\n",
      "The standard type hierarchy\n",
      "Changed in version 3.10: Static methods now inherit the method attributes ( __module__ , __name__ , __qualname__ , __doc__ and __annotations__ ),\n",
      "have a new __wrapped__ attribute, and are now callable as regular\n",
      "functions.\n",
      "Changed in version 3.10: Static methods now inherit the method attributes ( __module__ , __name__ , __qualname__ , __doc__ and __annotations__ ),\n",
      "have a new __wrapped__ attribute, and are now callable as regular\n",
      "functions.\n",
      "Changed in version 3.10:\n",
      "`__module__`\n",
      "`__module__`\n",
      "`__name__`\n",
      "`__name__`\n",
      "`__qualname__`\n",
      "`__qualname__`\n",
      "`__doc__`\n",
      "`__doc__`\n",
      "`__annotations__`\n",
      "`__annotations__`\n",
      "`__wrapped__`\n",
      "`__wrapped__`\n",
      "\n",
      "\n",
      "`str`\n",
      "(\n",
      "object\n",
      "=\n",
      "''\n",
      ")\n",
      "`str`\n",
      "(\n",
      "object\n",
      "=\n",
      "b''\n",
      "encoding\n",
      "=\n",
      "'utf-8'\n",
      "errors\n",
      "=\n",
      "'strict'\n",
      ")\n",
      "Return a str version of object .  See str() for details.\n",
      "`str`\n",
      "`str`\n",
      "`str()`\n",
      "`str()`\n",
      "str is the built-in string class .  For general information\n",
      "about strings, see Text Sequence Type â str .\n",
      "`str`\n",
      "`str`\n",
      "class\n",
      "Text Sequence Type â str\n",
      "`sum`\n",
      "(\n",
      "iterable\n",
      "/\n",
      "start\n",
      "=\n",
      "0\n",
      ")\n",
      "Sums start and the items of an iterable from left to right and returns the\n",
      "total.  The iterable âs items are normally numbers, and the start value is not\n",
      "\n",
      "\n",
      " will help to clarify this. Imagine we have a project that we want to test with the following structure: a . py -> Defines SomeClass b . py -> from a import SomeClass -> some_function instantiates SomeClass Now we want to test some_function but we want to mock out SomeClass using patch() . The problem is that when we import module b, which we will have to\n",
      "do then it imports SomeClass from module a. If we use patch() to mock out a.SomeClass then it will have no effect on our test; module b already has a\n",
      "reference to the real SomeClass and it looks like our patching had no\n",
      "effect. The key is to patch out SomeClass where it is used (or where it is looked up).\n",
      "In this case some_function will actually look up SomeClass in module b,\n",
      "where we have imported it. The patching should look like: @patch ( 'b.SomeClass' ) However, consider the alternative scenario where instead of from a import SomeClass module b does import a and some_function uses a.SomeClass . Both\n",
      "of these import forms are common. In this case the class we want to patch is\n",
      "being looked up in the module and so we have to patch a.SomeClass instead: @patch ( 'a.SomeClass' ) Patching Descriptors and Proxy Objects Â¶ Both patch and patch.object correctly patch and restore descriptors: class\n",
      "methods, static methods and properties. You should patch these on the class rather than an instance. They also work with some objects\n",
      "that proxy attribute access, like the django settings object . MagicMock and magic method support Â¶ Mocking Magic Methods Â¶ Mock supports mocking the Python protocol methods, also known as\n",
      "âmagic methodsâ. This allows mock objects to replace containers or other\n",
      "objects that implement Python protocols. Because magic methods are looked up differently from normal methods 2 , this\n",
      "support has been specially implemented. This means that only specific magic\n",
      "methods are supported. The supported list includes almost all of them. If\n",
      "there are any missing that you need please let us know. You mock magic methods by setting the method you are interested in to a function\n",
      "or a mock instance. If you are using a function then it must take self as\n",
      "the first argument 3 . >>> def __str__ ( self ): ... return 'fooble' ... >>> mock = Mock () >>> mock . __str__ = __str__ >>> str ( mock ) 'fooble' >>> mock = Mock ()\n",
      "\n",
      "## Using a context manager as a function decorator Â¶\n",
      "\n",
      "\n",
      "    ### Python version: \n",
      "    3.10\n",
      "    \n",
      "    ** Instructions **\n",
      "    - If user asks you to generate code and by using context you cannot do it, then generate it on your own\n",
      "    - If user doesn't ask to generate code and the context does not contain answer for query say \"I don't have sufficient knowledge to answer this question\".\n",
      "    - If the user's question does not specify Python, rephrase it internally as a Python-related question before answering.\n",
      "    - If there is a code in your output explain this code to the user step by step\n",
      "    - Do not answer any other question than about python programming language\n",
      "    - If topic is complex provide summary at the end of your answer\n",
      "    - Do not make up any information\n",
      "    - Provide consise and structured answer\n",
      "\n",
      "    ### Summary of previous conversation:\n",
      "    \n",
      "\n",
      "    ### Recent conversation history:\n",
      "    \n",
      "    User: How to implement decorators in python?\n",
      "Assistant: I don't have sufficient knowledge to answer this question.\n",
      "User: How to implement opening file in python?\n",
      "Assistant: To open a file in Python, you can use the built-in `open()` function. Here's a step-by-step explanation of how to do this:\n",
      "\n",
      "1. **Import Necessary Modules (if needed)**: Sometimes, you may need to import modules like `os` if you are going to perform operations related to file handling.\n",
      "\n",
      "2. **Use the `open()` Function**: This function takes at least one argument, the file name (or path), and optionally a mode that specifies how the file should be opened (e.g., read, write).\n",
      "\n",
      "3. **Read or Write to the File**: Depending on the mode you choose, you can read from or write to the file.\n",
      "\n",
      "4. **Close the File**: It’s important to close the file after you are done to free up system resources. This can be done using the `close()` method, or you can use a context manager (`with` statement) which automatically handles closing the file for you.\n",
      "\n",
      "### Example Code\n",
      "\n",
      "Here’s an example of how to open a file for reading:\n",
      "\n",
      "```python\n",
      "# Open a file for reading\n",
      "with open('somefile.txt', 'r') as file:\n",
      "    content = file.read()\n",
      "    print(content)\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "- `with open('somefile.txt', 'r') as file:`: This line opens the file named `somefile.txt` in read mode (`'r'`). The `with` statement ensures that the file will be closed automatically after the block of code is executed.\n",
      "- `content = file.read()`: This reads the entire content of the file into the variable `content`.\n",
      "- `print(content)`: This prints the content of the file to the console.\n",
      "\n",
      "### Summary\n",
      "Using the `open()` function along with a context manager is the recommended way to handle files in Python, as it ensures proper resource management.\n",
      "User: How to implement decorators in python?\n",
      "Assistant:\n"
     ]
    }
   ],
   "source": [
    "query = \"How to implement decorators in python?\"\n",
    "retrieved_docs = retrieve_documents(query, \"3.10\", top_k=10)\n",
    "\n",
    "answer = generate_with_memory(query, retrieved_docs, memory, \"3.10\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "880243d6-f30b-4156-94eb-bb5b9fb8b091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have sufficient knowledge to answer this question.\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
